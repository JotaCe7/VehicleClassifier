{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11b9c24",
   "metadata": {},
   "source": [
    "# Vehicle Classification\n",
    "\n",
    "## Evaluate your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from utils import utils\n",
    "from models import resnet_50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491a75b4",
   "metadata": {},
   "source": [
    "## Experiment settings\n",
    "\n",
    "Set here the two variables in the following way:\n",
    "\n",
    "- **CONFIG_YML:** assign the path to the config.yml file used for the experiment you want to evaluate\n",
    "- **WEIGHTS:** assign the path to the model weights (.h5 file) you want to evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7939dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_YML = \"../experiments/exp_001/config.yml\"\n",
    "WEIGHTS = \"../experiments/exp_001/model.07-4.4125.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643da00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oad the config file\n",
    "config = utils.load_config(CONFIG_YML)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "435199e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer the class names and also load the corresponding testing dataset.\n",
    "\n",
    "MODEL_CLASSES = utils.get_class_names(config)\n",
    "\n",
    "if len(MODEL_CLASSES) != config['model']['classes']:\n",
    "    raise ValueError(\n",
    "        \"Number of classes doesn't match between your model \"\n",
    "        \"and your data!\"\n",
    "    )\n",
    "\n",
    "_dirname, _ = os.path.split(config['data']['directory'])\n",
    "TEST_FOLDER = os.path.join(_dirname, 'test')\n",
    "\n",
    "if not os.path.exists(TEST_FOLDER):\n",
    "    raise ValueError(\"'test' folder not found!\")\n",
    "    \n",
    "if len(os.listdir(TEST_FOLDER)) != config['model']['classes']:\n",
    "    raise ValueError(\n",
    "        \"Number of classes doesn't match between your model \"\n",
    "        \"and your testing dataset!\"\n",
    "    )\n",
    "    \n",
    "if set(os.listdir(TEST_FOLDER)) != set(MODEL_CLASSES):\n",
    "    raise ValueError(\n",
    "        \"The name of the subfolders inside your test set \"\n",
    "        \"doesn't match with the model classes!\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85511441",
   "metadata": {},
   "source": [
    "## Load your model\n",
    "\n",
    "Use `resnet_50.create_model()` and remember to properly setup the model weights!\n",
    "\n",
    "Assign the model to the variable `cnn_model`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = resnet_50.create_model(weights=WEIGHTS)\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a33cbb",
   "metadata": {},
   "source": [
    "## Get predictions from testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce894dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     Get model predictions and the corresponding true labels\n",
    "#     so we can measure the accuracy\n",
    "\n",
    "predictions, labels = utils.predict_from_folder(\n",
    "    folder=TEST_FOLDER, \n",
    "    model=cnn_model, \n",
    "    input_size=config[\"data\"][\"image_size\"], \n",
    "    class_names=MODEL_CLASSES,\n",
    ")\n",
    "\n",
    "if len(predictions) != len(labels):\n",
    "    raise ValueError(\n",
    "        \"The lenght of predictions and labels lists doesn't match!\"\n",
    "    )\n",
    "\n",
    "if not isinstance(predictions[0], str):\n",
    "    raise ValueError(\n",
    "        \"Model predictions should be represented as string. E.g: 'Acura RL Sedan 2012'\"\n",
    "    )\n",
    "\n",
    "if not isinstance(labels[0], str):\n",
    "    raise ValueError(\n",
    "        \"Ground true labels should be represented as string. E.g: 'Acura RL Sedan 2012'\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b06098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true=labels, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8342c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true=labels, y_pred=predictions)\n",
    "\n",
    "print(f\"Your model accuracy is {acc:.4f}!\")\n",
    "\n",
    "if acc < .3:\n",
    "    raise ValueError(\"Your model accuracy is too low :(\\nYou can do it better! :)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aaiSP5-3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d04a6fd95e32fe637a00c4b779381388c3f0e735b5402173a360a886b35abd74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
